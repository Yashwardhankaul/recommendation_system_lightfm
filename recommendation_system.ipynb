{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "recommendation_system.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yashwardhankaul/recommendation_system_lightfm/blob/master/recommendation_system.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "5c5Ib4dXPiC1",
        "colab_type": "code",
        "outputId": "edd8b8b5-50af-4e5d-b828-24fc9b13140d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install lightfm\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting lightfm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/8e/5485ac5a8616abe1c673d1e033e2f232b4319ab95424b42499fabff2257f/lightfm-1.15.tar.gz (302kB)\n",
            "\u001b[K    100% |████████████████████████████████| 307kB 7.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lightfm) (1.14.6)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from lightfm) (1.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from lightfm) (2.18.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->lightfm) (2018.10.15)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->lightfm) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->lightfm) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->lightfm) (1.22)\n",
            "Building wheels for collected packages: lightfm\n",
            "  Running setup.py bdist_wheel for lightfm ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/eb/bb/ac/188385a5da6627956be5d9663928483b36da576149ab5b8f79\n",
            "Successfully built lightfm\n",
            "Installing collected packages: lightfm\n",
            "Successfully installed lightfm-1.15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9GVczp7cPk4T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from lightfm.datasets import fetch_movielens\n",
        "from lightfm import LightFM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "870tF7vpQDoo",
        "colab_type": "code",
        "outputId": "c5cadae5-1e95-41e0-bb43-15fb1e0c059a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "cell_type": "code",
      "source": [
        "help(fetch_movielens)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on function fetch_movielens in module lightfm.datasets.movielens:\n",
            "\n",
            "fetch_movielens(data_home=None, indicator_features=True, genre_features=False, min_rating=0.0, download_if_missing=True)\n",
            "    Fetch the `Movielens 100k dataset <http://grouplens.org/datasets/movielens/100k/>`_.\n",
            "    \n",
            "    The dataset contains 100,000 interactions from 1000 users on 1700 movies,\n",
            "    and is exhaustively described in its\n",
            "    `README <http://files.grouplens.org/datasets/movielens/ml-100k-README.txt>`_.\n",
            "    \n",
            "    Parameters\n",
            "    ----------\n",
            "    \n",
            "    data_home: path, optional\n",
            "        Path to the directory in which the downloaded data should be placed.\n",
            "        Defaults to ``~/lightfm_data/``.\n",
            "    indicator_features: bool, optional\n",
            "        Use an [n_items, n_items] identity matrix for item features. When True with genre_features,\n",
            "        indicator and genre features are concatenated into a single feature matrix of shape\n",
            "        [n_items, n_items + n_genres].\n",
            "    genre_features: bool, optional\n",
            "        Use a [n_items, n_genres] matrix for item features. When True with item_indicator_features,\n",
            "        indicator and genre features are concatenated into a single feature matrix of shape\n",
            "        [n_items, n_items + n_genres].\n",
            "    min_rating: float, optional\n",
            "        Minimum rating to include in the interaction matrix.\n",
            "    download_if_missing: bool, optional\n",
            "        Download the data if not present. Raises an IOError if False and data is missing.\n",
            "    \n",
            "    Notes\n",
            "    -----\n",
            "    \n",
            "    The return value is a dictionary containing the following keys:\n",
            "    \n",
            "    Returns\n",
            "    -------\n",
            "    \n",
            "    train: sp.coo_matrix of shape [n_users, n_items]\n",
            "         Contains training set interactions.\n",
            "    test: sp.coo_matrix of shape [n_users, n_items]\n",
            "         Contains testing set interactions.\n",
            "    item_features: sp.csr_matrix of shape [n_items, n_item_features]\n",
            "         Contains item features.\n",
            "    item_feature_labels: np.array of strings of shape [n_item_features,]\n",
            "         Labels of item features.\n",
            "    item_labels: np.array of strings of shape [n_items,]\n",
            "         Items' titles.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tDH1QjbcQUNm",
        "colab_type": "code",
        "outputId": "3f53620f-2342-4a4b-bf51-ff9c75920f89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2006
        }
      },
      "cell_type": "code",
      "source": [
        "import inspect\n",
        "print(inspect.getsource(fetch_movielens))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "def fetch_movielens(data_home=None, indicator_features=True, genre_features=False,\n",
            "                    min_rating=0.0, download_if_missing=True):\n",
            "    \"\"\"\n",
            "    Fetch the `Movielens 100k dataset <http://grouplens.org/datasets/movielens/100k/>`_.\n",
            "\n",
            "    The dataset contains 100,000 interactions from 1000 users on 1700 movies,\n",
            "    and is exhaustively described in its\n",
            "    `README <http://files.grouplens.org/datasets/movielens/ml-100k-README.txt>`_.\n",
            "\n",
            "    Parameters\n",
            "    ----------\n",
            "\n",
            "    data_home: path, optional\n",
            "        Path to the directory in which the downloaded data should be placed.\n",
            "        Defaults to ``~/lightfm_data/``.\n",
            "    indicator_features: bool, optional\n",
            "        Use an [n_items, n_items] identity matrix for item features. When True with genre_features,\n",
            "        indicator and genre features are concatenated into a single feature matrix of shape\n",
            "        [n_items, n_items + n_genres].\n",
            "    genre_features: bool, optional\n",
            "        Use a [n_items, n_genres] matrix for item features. When True with item_indicator_features,\n",
            "        indicator and genre features are concatenated into a single feature matrix of shape\n",
            "        [n_items, n_items + n_genres].\n",
            "    min_rating: float, optional\n",
            "        Minimum rating to include in the interaction matrix.\n",
            "    download_if_missing: bool, optional\n",
            "        Download the data if not present. Raises an IOError if False and data is missing.\n",
            "\n",
            "    Notes\n",
            "    -----\n",
            "\n",
            "    The return value is a dictionary containing the following keys:\n",
            "\n",
            "    Returns\n",
            "    -------\n",
            "\n",
            "    train: sp.coo_matrix of shape [n_users, n_items]\n",
            "         Contains training set interactions.\n",
            "    test: sp.coo_matrix of shape [n_users, n_items]\n",
            "         Contains testing set interactions.\n",
            "    item_features: sp.csr_matrix of shape [n_items, n_item_features]\n",
            "         Contains item features.\n",
            "    item_feature_labels: np.array of strings of shape [n_item_features,]\n",
            "         Labels of item features.\n",
            "    item_labels: np.array of strings of shape [n_items,]\n",
            "         Items' titles.\n",
            "    \"\"\"\n",
            "\n",
            "    if not (indicator_features or genre_features):\n",
            "        raise ValueError('At least one of item_indicator_features '\n",
            "                         'or genre_features must be True')\n",
            "\n",
            "    zip_path = _common.get_data(data_home,\n",
            "                                ('https://github.com/maciejkula/'\n",
            "                                 'lightfm_datasets/releases/'\n",
            "                                 'download/v0.1.0/movielens.zip'),\n",
            "                                'movielens100k',\n",
            "                                'movielens.zip',\n",
            "                                download_if_missing)\n",
            "\n",
            "    # Load raw data\n",
            "    try:\n",
            "        (train_raw, test_raw,\n",
            "         item_metadata_raw, genres_raw) = _read_raw_data(zip_path)\n",
            "    except zipfile.BadZipFile:\n",
            "        # Download was corrupted, get rid of the partially\n",
            "        # downloaded file so that we re-download on the\n",
            "        # next try.\n",
            "        os.unlink(zip_path)\n",
            "        raise ValueError('Corrupted Movielens download. Check your '\n",
            "                         'internet connection and try again.')\n",
            "\n",
            "    # Figure out the dimensions\n",
            "    num_users, num_items = _get_dimensions(_parse(train_raw),\n",
            "                                           _parse(test_raw))\n",
            "\n",
            "    # Load train interactions\n",
            "    train = _build_interaction_matrix(num_users,\n",
            "                                      num_items,\n",
            "                                      _parse(train_raw),\n",
            "                                      min_rating)\n",
            "    # Load test interactions\n",
            "    test = _build_interaction_matrix(num_users,\n",
            "                                     num_items,\n",
            "                                     _parse(test_raw),\n",
            "                                     min_rating)\n",
            "\n",
            "    assert train.shape == test.shape\n",
            "\n",
            "    # Load metadata features\n",
            "    (id_features, id_feature_labels,\n",
            "     genre_features_matrix, genre_feature_labels) = _parse_item_metadata(num_items,\n",
            "                                                                         item_metadata_raw,\n",
            "                                                                         genres_raw)\n",
            "\n",
            "    assert id_features.shape == (num_items, len(id_feature_labels))\n",
            "    assert genre_features_matrix.shape == (num_items, len(genre_feature_labels))\n",
            "\n",
            "    if indicator_features and not genre_features:\n",
            "        features = id_features\n",
            "        feature_labels = id_feature_labels\n",
            "    elif genre_features and not indicator_features:\n",
            "        features = genre_features_matrix\n",
            "        feature_labels = genre_feature_labels\n",
            "    else:\n",
            "        features = sp.hstack([id_features, genre_features_matrix]).tocsr()\n",
            "        feature_labels = np.concatenate((id_feature_labels,\n",
            "                                         genre_feature_labels))\n",
            "\n",
            "    data = {'train': train,\n",
            "            'test': test,\n",
            "            'item_features': features,\n",
            "            'item_feature_labels': feature_labels,\n",
            "            'item_labels': id_feature_labels}\n",
            "\n",
            "    return data\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ot_475gYQ3E4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = fetch_movielens(min_rating=4.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7YrI1wrsJtz4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f4afe259-c378-4e17-e4b4-f9498cc087c2"
      },
      "cell_type": "code",
      "source": [
        "#create model\n",
        "model = LightFM(loss='warp')\n",
        "#train model\n",
        "model.fit(data['train'], epochs=30, num_threads=2)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<lightfm.lightfm.LightFM at 0x7f0c5f10dfd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "SBiEgu_xKFhD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sample_recommendation(model, data, user_ids):\n",
        "\n",
        "    #number of users and movies in training data\n",
        "    n_users, n_items = data['train'].shape\n",
        "\n",
        "    #generate recommendations for each user we input\n",
        "    for user_id in user_ids:\n",
        "\n",
        "        #movies they already like\n",
        "        known_positives = data['item_labels'][data['train'].tocsr()[user_id].indices]\n",
        "\n",
        "        #movies our model predicts they will like\n",
        "        scores = model.predict(user_id, np.arange(n_items))\n",
        "        #rank them in order of most liked to least\n",
        "        top_items = data['item_labels'][np.argsort(-scores)]\n",
        "\n",
        "        #print out the results\n",
        "        print(\"User %s\" % user_id)\n",
        "        print(\"     Known positives:\")\n",
        "\n",
        "        for x in known_positives[:3]:\n",
        "            print(\"        %s\" % x)\n",
        "\n",
        "        print(\"     Recommended:\")\n",
        "\n",
        "        for x in top_items[:3]:\n",
        "            print(\"        %s\" % x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qXy0U93ZKJF-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "acc02b1e-407a-4302-8c0c-da645f0b5640"
      },
      "cell_type": "code",
      "source": [
        "sample_recommendation(model, data, [3, 25, 450])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User 3\n",
            "     Known positives:\n",
            "        Seven (Se7en) (1995)\n",
            "        Contact (1997)\n",
            "        Starship Troopers (1997)\n",
            "     Recommended:\n",
            "        Chasing Amy (1997)\n",
            "        L.A. Confidential (1997)\n",
            "        Boogie Nights (1997)\n",
            "User 25\n",
            "     Known positives:\n",
            "        Dead Man Walking (1995)\n",
            "        Star Wars (1977)\n",
            "        Fargo (1996)\n",
            "     Recommended:\n",
            "        Contact (1997)\n",
            "        Fargo (1996)\n",
            "        English Patient, The (1996)\n",
            "User 450\n",
            "     Known positives:\n",
            "        Contact (1997)\n",
            "        George of the Jungle (1997)\n",
            "        Event Horizon (1997)\n",
            "     Recommended:\n",
            "        G.I. Jane (1997)\n",
            "        Kiss the Girls (1997)\n",
            "        Scream (1996)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}